# í”„ë¡œì íŠ¸ ë¦¬ë·° - íƒ‘ ë‹¤ìš´ ì‹¤í–‰

ì•„í‚¤í…ì²˜, ì§„í–‰ ìƒí™©, ê¸°ìˆ  ê²°ì •ì— ì´ˆì ì„ ë§ì¶˜ í¬ê´„ì ì¸ í”„ë¡œì íŠ¸ ìˆ˜ì¤€ ë¦¬ë·°ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**ì¤‘ìš”ì‚¬í•­:**

- ì´ëŠ” ìµœê·¼ ë³€ê²½ ì‚¬í•­ì´ ì•„ë‹Œ ì „ì²´ í”„ë¡œì íŠ¸ ìƒíƒœì— ëŒ€í•œ ê³ ìˆ˜ì¤€ ë¦¬ë·°ì…ë‹ˆë‹¤.
- í”„ë¡œì íŠ¸ ë¬¸ì„œì— ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì€ í•œ, íƒ€ì„ë¼ì¸ê³¼ ì¼ì •ì€ ê´€ë ¨ì´ ì—†ìŠµë‹ˆë‹¤

## ì •í™•íˆ ë‹¤ìŒ 9ê°œ í•­ëª©ìœ¼ë¡œ TODO ìƒì„±

1. ë¦¬ë·° ë²”ìœ„ ë° íƒ€ì´ë° ë¶„ì„
2. í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ ìƒíƒœ ì‹¤í–‰ ë° í‰ê°€
3. í”„ë¡œì íŠ¸ ë¬¸ì„œ ì •ë ¬ í‰ê°€
4. ë§ˆì¼ìŠ¤í†¤ ë° ìŠ¤í”„ë¦°íŠ¸ ì§„í–‰ ìƒí™© ê²€í† 
5. ì½”ë“œë² ì´ìŠ¤ ì•„í‚¤í…ì²˜ ë° êµ¬ì¡° ë¶„ì„
6. íŒŒì¼ êµ¬ì„± ë° ì›Œí¬í”Œë¡œìš° ì¤€ìˆ˜ ê°ì‚¬
7. ê¸°ìˆ ì  ê²°ì • ë° ë³µì¡ì„± í‰ê°€
8. êµ¬í˜„ í’ˆì§ˆ ë¹„í‰ (John Carmack ê´€ì )
9. ê¶Œì¥ ì‚¬í•­ê³¼ í•¨ê»˜ í¬ê´„ì ì¸ í‰ê°€ ì œê³µ

ë‹¨ê³„ë³„ë¡œ ì§„í–‰í•˜ë©° ê° ë‹¨ê³„ì— ëŒ€í•œ ë‹¤ìŒ ì§€ì¹¨ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì„¸ìš”.

## ëª¨ë“  TODO í•­ëª©ì— ëŒ€í•œ ì„¸ë¶€ì‚¬í•­

### 1. ë¦¬ë·° ë²”ìœ„ ë° íƒ€ì´ë° ë¶„ì„

í™•ì¸: <$ARGUMENTS>

ë¹„ì–´ìˆë‹¤ë©´ ì „ì²´ í”„ë¡œì íŠ¸ ë¦¬ë·°ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ <$ARGUMENTS>ë¥¼ í•´ì„í•˜ì—¬ íŠ¹ì • ì´ˆì  ì˜ì—­(ë§ˆì¼ìŠ¤í†¤, ìŠ¤í”„ë¦°íŠ¸, ì•„í‚¤í…ì²˜ êµ¬ì„± ìš”ì†Œ ë“±)ì„ ì‹ë³„í•©ë‹ˆë‹¤. Argumentì— ëª…ì‹œë˜ì§€ ì•Šì€ í•œ `.aiwf/10_STATE_OF_PROJECT`ì˜ ì´ì „ í”„ë¡œì íŠ¸ ë¦¬ë·°ì™€ ë¹„êµí•˜ì§€ ë§ˆì„¸ìš”.

**ì¤‘ìš”:** ì´ ë¦¬ë·°ëŠ” ìµœê·¼ ë³€ê²½ì‚¬í•­ì˜ ë§¥ë½ì—ì„œ ì „ì²´ í”„ë¡œì íŠ¸ ìƒíƒœë¥¼ ì‚´í´ë´…ë‹ˆë‹¤.

**í•µì‹¬:** `.aiwf/00_PROJECT_MANIFEST.md`ë¥¼ **ë¨¼ì €** ì½ì–´ì„œ ë‹¤ìŒì„ ì´í•´í•˜ì„¸ìš”:

- í˜„ì¬ ë§ˆì¼ìŠ¤í†¤ ë° ìŠ¤í”„ë¦°íŠ¸ ìƒíƒœ
- ì™„ë£Œëœ ì‘ì—… vs ì§„í–‰ ì¤‘ì¸ ì‘ì—… vs ê³„íšëœ ì‘ì—…
- í™œì„± ìŠ¤í”„ë¦°íŠ¸ ëª©í‘œ ë° ê²°ê³¼ë¬¼

**ë§¥ë½ í™•ì¸:** ê¸°ëŠ¥ í‰ê°€ ì „ì—:

- `.aiwf/03_SPRINTS/`ë¡œ ì´ë™í•˜ì—¬ í˜„ì¬ ìŠ¤í”„ë¦°íŠ¸ ì°¾ê¸°
- ìŠ¤í”„ë¦°íŠ¸ ë©”íƒ€ íŒŒì¼ì„ ì½ì–´ ë²”ìœ„ ë‚´ì— ìˆëŠ” ê²ƒ ì´í•´í•˜ê¸°
- ìŠ¤í”„ë¦°íŠ¸ ë‚´ì—ì„œ ì™„ë£Œëœ íƒœìŠ¤í¬ vs ê³„íšëœ íƒœìŠ¤í¬ í™•ì¸
- í–¥í›„ ìŠ¤í”„ë¦°íŠ¸ê°€ ì œê³µí•  ë‚´ìš© ì´í•´í•˜ê¸°

**ë¦¬ë·° ì›ì¹™:** ì „ì²´ ë§ˆì¼ìŠ¤í†¤ ë²”ìœ„ê°€ ì•„ë‹Œ í˜„ì¬ ìŠ¤í”„ë¦°íŠ¸ ê²°ê³¼ë¬¼ì— ëŒ€í•´ í‰ê°€í•©ë‹ˆë‹¤.

### 2. í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ ìƒíƒœ ì‹¤í–‰ ë° í‰ê°€

**í•µì‹¬:** í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ ìƒíƒœëŠ” ìŠ¤í”„ë¦°íŠ¸/ë§ˆì¼ìŠ¤í†¤ ì§„í–‰ì˜ ì°¨ë‹¨ ê¸°ì¤€ì…ë‹ˆë‹¤.

- ì „ì²´ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰ì„ ìœ„í•´ test.md ëª…ë ¹ ì‚¬ìš© (@.claude/commands/aiwf/aiwf_test.md)
- í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„: í†µê³¼/ì‹¤íŒ¨/ê±´ë„ˆë›´ ê°œìˆ˜ ë° ì‹¤íŒ¨ ì¹´í…Œê³ ë¦¬
- í…ŒìŠ¤íŠ¸ ìƒíƒœ ì ìˆ˜ ê³„ì‚° (0-10 ìŠ¤ì¼€ì¼):
  - 10: 100% í†µê³¼ìœ¨, ì¸í”„ë¼ ë¬¸ì œ ì—†ìŒ
  - 8-9: >95% í†µê³¼ìœ¨, ì‚¬ì†Œí•œ ë¬¸ì œë§Œ ìˆìŒ
  - 6-7: 80-95% í†µê³¼ìœ¨, ì¼ë¶€ ë¹„í•µì‹¬ ì‹¤íŒ¨
  - 4-5: 60-80% í†µê³¼ìœ¨, ì¤‘ëŒ€í•œ ë¬¸ì œ
  - 0-3: <60% pass rate, critical infrastructure problems
- CATEGORIZE failures:
  - Infrastructure: Import errors, missing modules
  - Configuration: Environment variables, database connections
  - Logic: Assertion failures, actual bugs
  - Flaky: Intermittent failures
- DETERMINE blocking status:
  - Score < 6: BLOCKS sprint progression
  - Score < 8: BLOCKS milestone completion
  - Score < 4: TRIGGERS emergency escalation
- IDENTIFY root causes of any infrastructure failures
- TRACK trend vs previous review (improvement/degradation)
- ASSESS test strategy validity for scope of the project. Tests should be pragmatic and help assuring functionality but not get in the way of development progress too much.

### 3. Assess project documentation alignment

**USE PARALLEL AGENTS** to follow these steps:

- READ all core documents in `.aiwf/01_PROJECT_DOCS/` especially ARCHITECTURE.md
- READ current milestone requirements in `.aiwf/02_REQUIREMENTS/`
- READ architecture decisions in `.aiwf/05_ARCHITECTURE_DECISIONS` as they might extend/contradict other documents
- IDENTIFY any gaps between documentation and current implementation
- CHECK if the project is still following the documented architecture vision
- VERIFY that current code structure matches documented patterns

**IMPORTANT:** Documentation is our source of truth. Any deviation needs justification.

### 4. Review milestone and sprint progress

**USE PARALLEL AGENTS** to follow these steps:

- READ `.aiwf/00_PROJECT_MANIFEST.md` for current status
- ANALYZE completed sprints in `.aiwf/03_SPRINTS/`
- COMPARE actual progress against CURRENT SPRINT deliverables (not full milestone)
- DISTINGUISH between sprint-level tasks vs milestone-level features
- ASSESS if current sprint focus aligns with milestone goals

### 5. Analyze codebase architecture and structure

#

**USE PARALLEL AGENTS** to follow these steps:

- EXAMINE overall project structure and organization
- ANALYZE import patterns and dependency relationships
- REVIEW database models and API structure for consistency
- CHECK for architectural patterns: are we following DDD, clean architecture, etc.?
- IDENTIFY any architectural debt or inconsistencies

**Focus areas:**

- **Directory structure** â€” logical organization, separation of concerns
- **Dependencies** â€” are we over-engineering? unnecessary libraries?
- **Models/Schemas** â€” consistency, proper relationships, normalization
- **APIs** â€” RESTful design, proper HTTP methods, consistent patterns
- **Configuration** â€” environment management, secrets handling

### 6. Audit file organization and workflow compliance

**IMPORTANT:** Check for workflow discipline and architectural boundary violations.

- **Root directory audit** â€” identify files that don't belong in project root
- **Development scripts** â€” verify all dev scripts follow `run_dev.py` pattern
- **Test file organization** â€” check tests are in `tests/` directory, not scattered
- **Documentation placement** â€” verify docs are in proper locations
- **Temporary/experimental files** â€” flag any `.py` files that look ad-hoc or experimental

**File Organization Rules to Enforce:**

- **Development scripts** â€” MUST go through `run_dev.py`, not standalone files
- **Test files** â€” MUST be in `tests/` directory with proper naming (`test_*.py`)
- **Documentation** â€” MUST be in `docs/` or `.aiwf/01_PROJECT_DOCS/`
- **Configuration** â€” MUST follow established patterns (`.env.example`, `pyproject.toml`)
- **Temporary files** â€” SHOULD NOT exist in committed code

**Red Flags to Identify:**

- Multiple scripts doing similar things (duplicate functionality)
- Random `.py` files in root directory
- Test files outside `tests/` directory
- Development scripts bypassing `run_dev.py`
- Unclear file purposes or experimental code

**CRITICAL:** File proliferation indicates workflow breakdown. Flag for immediate cleanup task creation.

### 7. Evaluate technical decisions and complexity

- ASSESS complexity vs. business value ratio
- REVIEW choice of frameworks, libraries, and tools
- ANALYZE if current patterns will scale with project growth
- IDENTIFY areas where we might be over-complicating simple problems
- CHECK for premature optimization or under-optimization

**IMPORTANT:** Think like an experienced developer. Are we solving the right problems the right way?

### 8. Critique implementation quality (John Carmack perspective)

Think as John Carmack would: focus on simplicity, performance, and maintainability, but keep the projects goal in mind. Especially long term vision as well. Don't over simplify.

- **Simplicity:** Are we solving problems in the most straightforward way?
- **Performance:** Are there obvious performance issues or bottlenecks?
- **Maintainability:** Will a new developer understand this code in 6 months?
- **Robustness:** How does the system handle edge cases and failures?
- **Technical debt:** What shortcuts are we taking that will hurt us later?

Be **brutally honest**. Carmack-level critique means no sugar-coating but still staying true to the project's reality.
Be thorough and **go above and beyond** in your analysis - leave no stone unturned.

### 9. Provide comprehensive assessment with recommendations

**IMPORTANT:** Get current timestamp and create output file

- Get current timestamp using system date command
- Create filename: `YYYY-MM-DD-HH-MM-<judgment-slug>.md` in `.aiwf/10_STATE_OF_PROJECT/`
- Judgment slug should be 2-3 words describing overall project health (e.g., "solid-progress", "needs-focus", "critical-issues", "doing-great", "on-track")

**IMPORTANT:** Write full report to the timestamped file with this format:

```markdown
# Project Review - [YYYY-MM-DD HH:MM]

## ğŸ­ Review Sentiment

[3 emojis only - no explanations]

## Executive Summary

- **Result:** EXCELLENT | GOOD | NEEDS_WORK | CRITICAL_ISSUES
- **Scope:** What areas were reviewed
- **Overall Judgment:** [2-3 word assessment used in filename]

## Test Infrastructure Assessment

- **Test Suite Status**: [PASSING/FAILING/BLOCKED] (X/Y tests)
- **Test Pass Rate**: X% (Y passed, Z failed)
- **Test Health Score**: X/10
- **Infrastructure Health**: [HEALTHY/DEGRADED/BROKEN]
  - Import errors: [count]
  - Configuration errors: [count]
  - Fixture issues: [count]
- **Test Categories**:
  - Unit Tests: X/Y passing
  - Integration Tests: X/Y passing
  - API Tests: X/Y passing
- **Critical Issues**:
  - [List of blocking test infrastructure problems]
  - [Module import mismatches]
  - [Environment configuration failures]
- **Sprint Coverage**: [% of sprint deliverables with passing tests]
- **Blocking Status**: [CLEAR/BLOCKED - reason]
- **Recommendations**:
  - [Immediate fixes required]
  - [Test infrastructure improvements needed]

## Development Context

- **Current Milestone:** [ID and status from manifest]
- **Current Sprint:** [ID and focus]
- **Expected Completeness:** [what SHOULD be done at this stage]

## Progress Assessment

- **Milestone Progress:** [percentage complete]
- **Sprint Status:** [current sprint assessment]
- **Deliverable Tracking:** [what's done vs planned]

## Architecture & Technical Assessment

- **Architecture Score:** 1-10 rating with explanation
- **Technical Debt Level:** LOW | MEDIUM | HIGH with specific examples
- **Code Quality:** [overall assessment with examples]

## File Organization Audit

- **Workflow Compliance:** GOOD | NEEDS_ATTENTION | CRITICAL_VIOLATIONS
- **File Organization Issues:** [list any misplaced files, duplicate scripts, etc.]
- **Cleanup Tasks Needed:** [specific file moves/deletions/consolidations required]

## Critical Findings

### Critical Issues (Severity 8-10)

[Lists of must-fix problems headed with #### heading, one empty line and then list of details]

### Improvement Opportunities (Severity 4-7)

[List of recommended enhancements headed with #### heading, one empty line and then list of details]

## John Carmack Critique ğŸ”¥

[Top 3 brutally honest observations about technical decisions]

## Recommendations

Based on your findings recommend Action items - chose whatever fits your findings

- **Important fixes:** What needs to be fixed immediately?
- **Optional fixes/changes:** What would still be recommended though optional?
- **Next Sprint Focus:** Can the user move to the next sprint?
```

**IMPORTANT:** Be specific with file paths and line numbers. This review should be actionable and permanently archived.
